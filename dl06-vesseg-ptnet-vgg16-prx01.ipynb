{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":33926,"databundleVersionId":3116373,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision.models import vgg16_bn,VGG16_BN_Weights\nimport torch.nn.functional as F\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport os\nimport PIL\nfrom PIL import Image\nfrom torchvision.transforms import Normalize, ToTensor, Compose\nfrom matplotlib import pyplot as plt\nimport math\nimport pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device=torch.device(type=\"cuda\", index=0)\nelse:\n    device=torch.device(type=\"cpu\", index=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img=Image.open('/kaggle/input/sai-vessel-segmentation2/all/train/21_training.tif')\nmask=Image.open('/kaggle/input/sai-vessel-segmentation2/all/train/21_manual1.gif')\n\nprint(img.size)\nprint(np.array(img).shape, np.array(mask).shape)\nprint(np.unique(mask))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainCustomDS(Dataset):\n    def __init__(self,path,transform=None):\n        super().__init__()\n        self.path=path\n        _,_,self.filepaths=next(os.walk(path))\n        self.length=16\n        self.transform=Compose([\n            ToTensor(), \n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225]\n            )\n        ])\n        \n    \n    def __len__(self):\n        return self.length\n    \n    def __getitem__(self,idx):\n        idx = idx + 21\n        path = self.path + str(idx) + \"_training.tif\"\n        img = self._get_image(path)\n        img = self.transform(img)\n        \n        path = self.path + str(idx) + \"_manual1.gif\"\n        mask = np.array(self._get_image(path))\n        mask = torch.from_numpy(mask).type(torch.long)\n        mask[mask==255]=1\n                      \n        return img, mask\n    \n    def _get_image(self, path, size = 256):\n        img = Image.open(path)\n        rimg = img.resize((size,size),PIL.Image.NEAREST)\n        return rimg\n\nclass ValCustomDS(Dataset):\n    def __init__(self,path,transform=None):\n        super().__init__()\n        self.path=path\n        _,_,self.filepaths=next(os.walk(path))\n        self.length=int(len(self.filepaths)/2)-16\n        self.transform=Compose([ToTensor(), Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n        \n    \n    def __len__(self):\n        return self.length\n    \n    def __getitem__(self,idx):\n        idx=idx+37\n        path=self.path + str(idx) + \"_training.tif\"\n        img=self._get_image(path)\n        img=self.transform(img)\n        \n        path=self.path + str(idx) + \"_manual1.gif\"\n        mask=self._get_image(path)\n        mask=np.array(mask)\n        mask=torch.from_numpy(mask).type(torch.long)\n        mask[mask==255]=1\n                      \n        return img, mask\n    \n    def _get_image(self, path, size = 256):\n        img = Image.open(path)\n        rimg = img.resize((size,size),PIL.Image.NEAREST)\n        return rimg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainDS=TrainCustomDS(\"/kaggle/input/sai-vessel-segmentation2/all/train/\")\nvalDS=ValCustomDS(\"/kaggle/input/sai-vessel-segmentation2/all/train/\")\n\nbatch_size=4\n\ntrainDL=DataLoader(dataset=trainDS,batch_size=batch_size,shuffle=True)\nvalDL=DataLoader(dataset=valDS,batch_size=batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNET_Full(nn.Module):\n    def __init__(self, encoder, center, decoder):\n        super().__init__()\n        self.encoder=encoder\n        self.center=center\n        self.decoder=decoder\n    \n    def forward(self,x):\n        enc=self.encoder(x)\n        cen=self.center(enc[-1])\n        y=self.decoder(cen, enc)\n        return y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self,pretrained_network):\n        super().__init__()\n        self.encoder=pretrained_network\n    \n    def forward(self,x):\n        enc_out=[]\n        for layer in self.encoder.features:\n                x=layer(x)\n                enc_out.append(x)\n                        \n        return enc_out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Center(nn.Sequential):\n  def __init__(self):\n        conv1=nn.Conv2d(512,1024,3,padding=1)\n        bn1=nn.BatchNorm2d(1024)\n        rl1=nn.ReLU()\n\n        conv2=nn.Conv2d(1024,1024,3,padding=1)\n        bn2=nn.BatchNorm2d(1024)\n        rl2=nn.ReLU()\n        \n        super().__init__(conv1,bn1,rl1,conv2,bn2,rl2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n               \n        self.rl=nn.ReLU()\n                        \n        self.conv5_up=nn.Conv2d(1024,512,3,padding=1)\n        self.conv5_1=nn.Conv2d(1024,512,3,padding=1)\n        self.bn5_1=nn.BatchNorm2d(512)\n        self.conv5_2=nn.Conv2d(512,512,3,padding=1)\n        self.bn5_2=nn.BatchNorm2d(512)\n        self.conv5_3=nn.Conv2d(512,512,3,padding=1)\n        self.bn5_3=nn.BatchNorm2d(512)\n        \n        self.conv4_up=nn.Conv2d(512,512,3,padding=1)\n        self.conv4_1=nn.Conv2d(1024,512,3,padding=1)\n        self.bn4_1=nn.BatchNorm2d(512)\n        self.conv4_2=nn.Conv2d(512,512,3,padding=1)\n        self.bn4_2=nn.BatchNorm2d(512)\n        self.conv4_3=nn.Conv2d(512,512,3,padding=1)\n        self.bn4_3=nn.BatchNorm2d(512)\n        \n        self.conv3_up=nn.Conv2d(512,256,3,padding=1)\n        self.conv3_1=nn.Conv2d(512,256,3,padding=1)\n        self.bn3_1=nn.BatchNorm2d(256)\n        self.conv3_2=nn.Conv2d(256,256,3,padding=1)\n        self.bn3_2=nn.BatchNorm2d(256)\n        self.conv3_3=nn.Conv2d(256,256,3,padding=1)\n        self.bn3_3=nn.BatchNorm2d(256)\n        \n        self.conv2_up=nn.Conv2d(256,128,3,padding=1)\n        self.conv2_1=nn.Conv2d(256,128,3,padding=1)\n        self.bn2_1=nn.BatchNorm2d(128)\n        self.conv2_2=nn.Conv2d(128,128,3,padding=1)\n        self.bn2_2=nn.BatchNorm2d(128)\n        \n        self.conv1_up=nn.Conv2d(128,64,3,padding=1)\n        self.conv1_1=nn.Conv2d(128,64,3,padding=1)\n        self.bn1_1=nn.BatchNorm2d(64)\n        self.conv1_2=nn.Conv2d(64,64,3,padding=1)\n        self.bn1_2=nn.BatchNorm2d(64)\n        \n        self.convfinal=nn.Conv2d(64,2,kernel_size=1)\n    \n    def forward(self,x, encoder_features_output):\n        x=F.interpolate(x,scale_factor=2, mode=\"nearest\")\n        x=self.conv5_up(x)\n        x=self.rl(x)\n        x=torch.cat((x,encoder_features_output[42]),dim=1)\n        x=self.conv5_1(x)\n        x=self.bn5_1(x)\n        x=self.rl(x)\n        x=self.conv5_2(x)\n        x=self.bn5_2(x)\n        x=self.rl(x)\n        x=self.conv5_3(x)\n        x=self.bn5_3(x)\n        x=self.rl(x)\n        \n        x=F.interpolate(x,scale_factor=2, mode=\"nearest\")\n        x=self.conv4_up(x)\n        x=self.rl(x)\n        x=torch.cat((x,encoder_features_output[32]),dim=1)\n        x=self.conv4_1(x)\n        x=self.bn4_1(x)\n        x=self.rl(x)\n        x=self.conv4_2(x)\n        x=self.bn4_2(x)\n        x=self.rl(x)\n        x=self.conv4_3(x)\n        x=self.bn4_3(x)\n        x=self.rl(x)\n        \n        x=F.interpolate(x,scale_factor=2, mode=\"nearest\")\n        x=self.conv3_up(x)\n        x=self.rl(x)\n        x=torch.cat((x,encoder_features_output[22]),dim=1)\n        x=self.conv3_1(x)\n        x=self.bn3_1(x)\n        x=self.rl(x)\n        x=self.conv3_2(x)\n        x=self.bn3_2(x)\n        x=self.rl(x)\n        x=self.conv3_3(x)\n        x=self.bn3_3(x)\n        x=self.rl(x)\n        \n        x=F.interpolate(x,scale_factor=2, mode=\"nearest\")\n        x=self.conv2_up(x)\n        x=self.rl(x)\n        x=torch.cat((x,encoder_features_output[12]),dim=1)\n        x=self.conv2_1(x)\n        x=self.bn2_1(x)\n        x=self.rl(x)\n        x=self.conv2_2(x)\n        x=self.bn2_2(x)\n        x=self.rl(x)\n        \n        x=F.interpolate(x,scale_factor=2, mode=\"nearest\")\n        x=self.conv1_up(x)\n        x=self.rl(x)\n        x=torch.cat((x,encoder_features_output[5]),dim=1)\n        x=self.conv1_1(x)\n        x=self.bn1_1(x)\n        x=self.rl(x)\n        x=self.conv1_2(x)\n        x=self.bn1_2(x)\n        x=self.rl(x)\n        \n        logits=self.convfinal(x)\n        \n        return logits","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(dataloader, model,loss_fn, optimizer):\n    model.train()\n    track_loss=0\n    XintY=0\n    X=0\n    Y=0\n    for i, (imgs, masks) in enumerate(dataloader):\n        imgs=imgs.to(device)\n        masks=masks.to(device)\n        \n        preds=model(imgs)\n        \n        loss=loss_fn(preds,masks)\n        \n        track_loss+=loss.item()\n        \n        predclass=torch.argmax(preds,dim=1)\n        \n        Y+=predclass.sum().item()\n        X+=masks.sum().item()\n        \n        \n        predclass[predclass==0]=2\n        \n        XintY+=(predclass==masks).type(torch.float).sum().item()\n        \n        print(\"Trainig Batch\",i+1,\":\")\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        running_loss=round(track_loss/(i+1),2)\n        running_dice_coef=round(((2*XintY)/(X+Y)),2)\n        \n        print(\"Training Batch\", i+1,\":\",\"/\",len(dataloader), \"Running Loss:\",running_loss, \"Running Dice_Coef:\",running_dice_coef)\n            \n    # Running = Epoch --- at end of epoch\n    return running_loss, running_dice_coef\n\n\ndef val_one_epoch(dataloader, model,loss_fn):\n    model.eval()\n    track_loss=0\n    XintY=0\n    X=0\n    Y=0\n    with torch.no_grad():\n        for i, (imgs, masks) in enumerate(dataloader):\n            imgs=imgs.to(device)\n            masks=masks.to(device)\n            \n            preds=model(imgs)\n            \n            loss=loss_fn(preds,masks)\n            \n            track_loss+=loss.item()\n            \n            predclass=torch.argmax(preds,dim=1)\n            \n            Y+=predclass.sum().item()\n            X+=masks.sum().item()\n            \n            predclass[predclass==0]=2\n            \n            XintY+=(predclass==masks).type(torch.float).sum().item()\n            \n            print(\"Validation Batch\",i+1,\":\")\n            \n\n            running_loss=round(track_loss/(i+1),2)\n            running_dice_coef=round(((2*XintY)/(X+Y)),2)\n            \n            print(\"Validation Batch\", i+1,\":\",\"/\",len(dataloader), \"Running Loss:\",running_loss, \"Running Dice_Coef:\",running_dice_coef)\n            \n \n    return running_loss, running_dice_coef","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training on Split Data","metadata":{}},{"cell_type":"code","source":"pretrained_network=vgg16_bn(weights=VGG16_BN_Weights.DEFAULT)\n\nfor param in pretrained_network.features.parameters():\n    param.requires_grad=False\n\nencoder=Encoder(pretrained_network).to(device)\ncenter=Center().to(device)\ndecoder=Decoder().to(device)\n\nmodel=UNET_Full(encoder,center, decoder).to(device)\n\nloss_fn=nn.CrossEntropyLoss()\nlr=0.001\noptimizer=torch.optim.Adam(params=model.parameters(), lr=lr)\nn_epochs=40\n\nfor i in range(n_epochs):\n    print(\"Epoch No:\",i+1)\n    train_epoch_loss, train_epoch_dice_coef=train_one_epoch(trainDL,model,loss_fn,optimizer)\n    print(\"Training Epoch Loss:\", train_epoch_loss, \"Training Epoch Dice_Coef:\", train_epoch_dice_coef)\n    val_epoch_loss, val_epoch_dice_coef=val_one_epoch(valDL,model,loss_fn)\n    print(\"Validation Epoch Loss:\", val_epoch_loss, \"Validation Epoch Dice_Coef:\", val_epoch_dice_coef)\n    print(\"--------------------------------------------------\")\n\n\n# Fine-Tuning\nfor param in pretrained_network.features.parameters():\n    param.requires_grad=True\n\nn_epochs=40  \nfor i in range(n_epochs):\n    print(\"Epoch No:\",i+1)\n    train_epoch_loss, train_epoch_dice_coef=train_one_epoch(trainDL,model,loss_fn,optimizer)\n    print(\"Training Epoch Loss:\", train_epoch_loss, \"Training Epoch Dice_Coef:\", train_epoch_dice_coef)\n    val_epoch_loss, val_epoch_dice_coef=val_one_epoch(valDL,model,loss_fn)\n    print(\"Validation Epoch Loss:\", val_epoch_loss, \"Validation Epoch Dice_Coef:\", val_epoch_dice_coef)\n    print(\"--------------------------------------------------\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotres(img,pred,mask=None):\n    img[0,:,:]=img[0,:,:]*0.229 + 0.485\n    img[1,:,:]=img[1,:,:]*0.224 + 0.456\n    img[2,:,:]=img[2,:,:]*0.225 + 0.406\n    if mask!=None:\n        print(\"Image Shape:\",img.shape,\"Mask Shape:\", mask.shape, \"Pred Shape:\",pred.shape, \"Image dtype\", img.dtype, \"Mask dtype\",mask.dtype, \"Pred dtype\",pred.dtype)\n        print(\"Mask Unique:\",mask.unique())\n    else:\n        print(\"Image Shape:\",img.shape, \"Pred Shape:\", pred.shape, \"Image dtype:\",img.dtype, \"Pred dtype:\",pred.dtype)\n    \n    print(\"Pred Unique:\",pred.unique())\n    \n    plt.figure(figsize=(10,5))\n    \n    plt.subplot(1,3,1)\n    plt.title(\"Original Image 512 x 512\")\n    plt.imshow(torch.permute(img.cpu(),(1,2,0)))\n    \n    if mask!=None:\n        plt.subplot(1,3,2)\n        plt.title(\"Mask Image  512 x 512\")\n        plt.imshow(mask.cpu())\n    \n    plt.subplot(1,3,3)\n    plt.title(\"Predicted Image  512 x 512\")\n    plt.imshow(pred.cpu())\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs,masks=next(iter(valDL))\nmodel.eval()\n\nimgs=imgs.to(device)\nmasks=masks.to(device)\n\nwith torch.no_grad():\n    preds=model(imgs)\n    \n    predclass=torch.argmax(preds,dim=1)\n            \n    Y=predclass.sum().item()\n    X=masks.sum().item()\n            \n    predclass[predclass==0]=2\n    \n    XintY=(predclass==masks).type(torch.float).sum().item()\n        \n    dice_coef=round((2*XintY)/(X+Y),2)\n    \n    \nprint(\"Validation Dice Coef:\",dice_coef)\n\npredclass[predclass==2]=0\nplotres(imgs[0],predclass[0],masks[0])\nplotres(imgs[1],predclass[1],masks[1])\nplotres(imgs[2],predclass[2],masks[2])\nplotres(imgs[3],predclass[3],masks[3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training on Full Data","metadata":{}},{"cell_type":"code","source":"trainDS=TrainCustomDS(\"/kaggle/input/sai-vessel-segmentation2/all/train/\", \"yes\")\nbatch_size=4\nn_epochs=40\ntrainDL=DataLoader(dataset=trainDS,batch_size=batch_size,shuffle=True)\n\nfor i in range(n_epochs):\n    print(\"Epoch No:\",i+1)\n    train_epoch_loss, train_epoch_dice_coef=train_one_epoch(trainDL,model,loss_fn,optimizer)\n    print(\"Training Epoch Loss:\", train_epoch_loss, \"Training Epoch Dice_Coef:\", train_epoch_dice_coef)\n    print(\"--------------------------------------------------\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestCustomDS(Dataset):\n    def __init__(self,path):\n        super().__init__()\n        self.path=path\n        _,_,self.filepaths=next(os.walk(path))\n        self.length=len(self.filepaths)\n        self.transform=Compose([ToTensor(), Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n    \n    def __len__(self):\n        return self.length\n    \n    def __getitem__(self,idx):\n        idx=idx+1\n        if idx <= 9:\n            path=self.path + \"0\" + str(idx) + \"_test.tif\"\n        else:\n            path=self.path + str(idx) + \"_test.tif\"\n        \n        img=self._get_image(path)\n        img=self.transform(img)\n        \n        return img\n    \n    def _get_image(self, path, size = 256):\n        img = Image.open(path)\n        rimg = img.resize((size,size),PIL.Image.NEAREST)\n        return rimg\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testDS=TestCustomDS(\"/kaggle/input/sai-vessel-segmentation2/all/test/\")\n\nbatch_size=2\ntestDL=DataLoader(dataset=testDS,batch_size=batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_one_epoch(dataloader, model):\n    model.eval()\n    outputs=[]\n    for i, imgs in enumerate(dataloader):\n        imgs=imgs.to(device)\n        preds=model(imgs)\n               \n        with torch.no_grad():\n            for i in range(preds.shape[0]):\n                pred=preds[i,:,:,:]\n                pred=torch.argmax(pred,dim=0).cpu()\n                \n                plotres(imgs[i],pred)\n                \n                predf=pred.flatten()\n                \n                pixelidx=np.where(predf==1)[0]+1\n                \n                run_lengths=[]\n                \n                for pxid in pixelidx:\n                    if len(run_lengths)==0:\n                        run_lengths.extend((pxid,1))\n                    elif pxid>prev+1:\n                        run_lengths.extend((pxid,1))\n                    else:\n                        run_lengths[-1]+=1\n                    prev=pxid\n                \n                output = ' '.join([str(r) for r in run_lengths])\n                \n                outputs.append(output)\n    return outputs\n\noutputs=eval_one_epoch(testDL,model)\ndf=pd.DataFrame(columns=['Id','Predicted'])   \ndf['Id']=[str(i) for i in range(20)]\ndf['Predicted']=outputs\ndf.to_csv(\"submission.csv\", index=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}